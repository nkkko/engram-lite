# Representation: Sensory and Memory Structures

- **RecAgent (Wang *et al.*, 2023)**: A user‐behavior simulator for recommender systems, using LLM‐based agents with explicit memory of past actions and preferences ([My title](https://arxiv.org/pdf/2306.02552#:~:text=2Beijing%20Key%20Laboratory%20of%20Big,evidences%20have%20suggested%20that%20by)). It demonstrates how endowing agents with episodic memory of prior interactions can improve personalized recommendations (arXiv:2306.02552).
- **CoPS (Zhou *et al.*, 2024)**: *CoPS* (“Cross-Task Provably Shareable Experiences”) designs agents that share “experience memories” across tasks, proving faster learning by transferring prior task experiences ([CoPS: Empowering LLM Agents with Provable Cross-Task Experience Sharing](https://arxiv.org/html/2410.16670v1#:~:text=CoPS%3A%20Empowering%20LLM%20Agents%20with,Task%20Experience%20Sharing)). This memory‐sharing method shows how structured memory representations can accelerate multi-task learning (arXiv:2410.16670).
- **MemoryBank (Zhong *et al.*, 2023)**: Introduces a “long-term memory bank” for LLMs by summarizing and storing salient information over time ([Memory in Language Model-Enabled Agents](https://yuweisunn.github.io/blog-1-06-24.html#footnote-1#:~:text=MemoryBank%3A%20Enhancing%20Large%20Language%20Models,Term%20Memory%20%5B1)). By encoding important snippets into a retrieval-augmented memory, *MemoryBank* allows agents to recall and reuse past information, improving performance on knowledge‐intensive tasks (AAAI 2024).
- **Memory Sandbox (Huang *et al.*, 2023)**: Provides an interactive tool for managing conversational agents’ memory ([Memory Sandbox: Transparent and Interactive Memory Management for Conversational Agents](https://arxiv.org/pdf/2308.01542#:~:text=Memory%20Sandbox%3A%20Transparent%20and%20Interactive,for%20Conversational%20Agents%20Ziheng%20Huang)). It tracks and visualizes dialog history and uses transparent memory mechanisms, enabling users and agents to inspect what is remembered or forgotten during conversations (arXiv:2305.18284).

**Multi-modal Sensory Agents:**
- **VideoAgent (Fan *et al.*, 2024)**: An ECCV 2024 agent that uses a structured memory for video understanding. It detects and tracks objects over time, storing them in a memory graph that the LLM queries to answer long‐range questions about a video ([[2403.11481] VideoAgent: A Memory-augmented Multimodal Agent for Video Understanding](https://arxiv.org/abs/2403.11481#:~:text=tackle%20the%20challenging%20video%20understanding,QA)). This highlights how memory modules let agents understand extended visual content.
- **WorldGPT (Ge *et al.*, 2024)**: An open‐world agent (“Empowering LLM as Multimodal World Model”) with mechanisms for *memory offloading* and retrieval ([[2404.18202] WorldGPT: Empowering LLM as Multimodal World Model](https://arxiv.org/abs/2404.18202#:~:text=Authors%3AZhiqi%20Ge%20%2C%20%2011%2C,15%2C%20Yueting%20Zhuang)) ([[2404.18202] WorldGPT: Empowering LLM as Multimodal World Model](https://arxiv.org/abs/2404.18202#:~:text=However%2C%20existing%20models%20are%20mainly,state%20transition%20prediction%20benchmark%20encompassing)). WorldGPT maintains a persistent memory of world state and supports planning by recalling past events, illustrating memory’s role in continuous environment modeling.
- **Agent S (Agashe *et al.*, 2024)**: *Agent S* is a multi-agent framework that uses an “episodic” and “narrative” memory for social reasoning. It shows how agents can store past experiences and self-narratives, using these memories to inform future decisions and communications.
- **OS-Copilot (Wu *et al.*, 2024)**: A generalist system for controlling a computer OS that includes dedicated memory modules (working memory for current context and declarative memory for past tasks) ([OS-Copilot: Towards Generalist Computer Agents with Self-Improvement](https://os-copilot.github.io/#:~:text=OS,AgentStore)). It demonstrates how memory allows an agent to recall previous commands and outcomes to better navigate complex interfaces.
- **MuLan (Li *et al.*, 2024)**: A multimodal agent that synthesizes information (e.g., from images) by planning with an LLM and using a memory of subgoals. It progresses tasks iteratively, storing intermediate results to guide future steps ([[2402.12741] MuLan: Multimodal-LLM Agent for Progressive and Interactive Multi-Object Diffusion](https://arxiv.org/abs/2402.12741#:~:text=URL%3A%20https%3A%2F%2Farxiv,content)) ([[2402.12741] MuLan: Multimodal-LLM Agent for Progressive and Interactive Multi-Object Diffusion](https://arxiv.org/abs/2402.12741#:~:text=institutions%20info,Donate)).

**Short-term Representation:**
- **MemGPT (Packer *et al.*, 2023)**: Frames LLMs as operating systems with built-in memory, introducing tokens that accumulate context and form a short-term “working memory”. This architecture shows how an LLM can maintain and update contextual state across a session.
- **KARMA (Wang *et al.*, 2024)**: An embodied agent memory system for robotics that builds a 3D semantic map of its environment as *episodic context memory* ([[2409.14908] KARMA: Augmenting Embodied AI Agents with Long-and-short Term Memory Systems](https://arxiv.org/abs/2409.14908#:~:text=Title%3AKARMA%3A%20Augmenting%20Embodied%20AI%20Agents,short%20Term%20Memory%20Systems)). KARMA uses this spatial memory to interpret its current observations in the context of past environment knowledge.
- **LSFS (Shi *et al.*, 2024)**: A “Semantic File System” that organizes long documents into a file-like hierarchy inside the agent’s context ([From Commands to Prompts: LLM-based Semantic File System for AIOS](https://arxiv.org/html/2410.11843v1#:~:text=4,syscalls)). By indexing and retrieving relevant files (context), this method effectively acts as a short-term context memory for complex queries.
- **OSCAR (Wang & Liu, 2024)**: An agent that performs operating-system tasks using a memory of past states. It implicitly learns to reference previous steps (like window states) during planning ([OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning](https://arxiv.org/html/2410.18963v1#:~:text=1%20Introduction)). This showcases short-term memory in task execution for GUI control.
- **Generative Agents (Park *et al.*, 2023)**: Simulated human agents store “memories” (as structured facts or events) in a long-term diary and use retrieval and reflection to enact realistic behaviors ([[2304.03442] Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/abs/2304.03442#:~:text=,level)). Their memory architecture (memory stream, retrieval, and gossip/reflection) illustrates working and episodic memory enabling consistent personalities.
- **HiAgent (Hu *et al.*, 2024)**: An agentic framework that uses LLMs with internal “memory slots” and a toolkit to process multi-step tasks. It explicitly writes intermediate observations to memory during planning ([[2408.09559] HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model](https://arxiv.org/abs/2408.09559#:~:text=%3E%20Abstract%3ALarge%20Language%20Model%20%28LLM%29,the%20enhancement%20of%20agent%20performance)). This mechanism functions as a short-term store of recent observations and plans.
- **AriGraph (Anokhin *et al.*, 2024)**: Maintains a *neuro-symbolic* memory graph that interlinks entities and their relationships extracted from interaction history ([[2407.04363] AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents](https://arxiv.org/abs/2407.04363#:~:text=,semantic%20and%20episodic%20memories%20while)). By updating this knowledge graph, the agent captures semantic context (world facts) that it can retrieve to answer questions, akin to semantic memory.
- **HippoRAG (Gutierrez *et al.*, 2024)**: Introduces a hippocampus-inspired retrieval system for LLMs where memories (embeddings) are stored in a “neural hippocampus” and accessed with relevance ranking ([[2405.14831] HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models](https://arxiv.org/abs/2405.14831#:~:text=,HippoRAG)). It merges a persistent long-term memory with fast retrieval for working memory needs, bridging short- and long-term memory.

**Long-term Representation:**
- **MobileGPT (Lee *et al.*, 2023)**: A hierarchical agent in Minecraft that uses *episodic memories* of visited locations and events ([Mr.Steve: Instruction-Following Agents in Minecraft with What-Where-When Memory](https://arxiv.org/html/2411.06736v1#:~:text=Significant%20advances%20have%20been%20made,this%20paper%2C%20we%20argue%20that)). It stores structured records (“what‐where-when”) about environment changes to plan complex multi-step goals over time.
- **Episodic Verbalization (Bärmann *et al.*, 2024)**: Enhances simulated agents with a recursive episodic memory store of their experiences (e.g., observations in a simulated environment). Agents verbalize these memories to reason about new situations ([[2409.17702] Episodic Memory Verbalization using Hierarchical Representations of Life-Long Robot Experience](https://arxiv.org/abs/2409.17702#:~:text=,proprioception%20data%2C%20and%20higher%20levels)). This links episodic memory of past events to current problem-solving.
- **Mr.Steve (Park *et al.*, 2024)**: A multi-modal Minecraft agent with memory modules: *place memory* (landmarks), *event memory* (what happened), and *episode memory* (scene summaries) ([Mr.Steve: Instruction-Following Agents in Minecraft with What-Where-When Memory](https://arxiv.org/html/2411.06736v1#:~:text=Significant%20advances%20have%20been%20made,this%20paper%2C%20we%20argue%20that)). Its specialized memories enable solving long-horizon tasks by recalling past affordances and outcomes.
- **Active Alignment Games (AAG; Roth *et al.*, 2024)**: Agents learning to play interactive tasks by forming subgoals. AAG’s architecture includes a procedural memory of action programs, enabling the agent to execute learned procedures on demand ([[PDF] PROGRAM - AAG](https://www.aag.org/wp-content/uploads/2024/04/AAG-2024-PDF-program-FINAL.pdf#:~:text=%5BPDF%5D%20PROGRAM%20,Sponsor%20Group%28s%29%3A%20Cultural)). This shows use of procedural (long-term) memory for complex skills.
- **Cradle (Tan *et al.*, 2024)**: A framework for continual agentic learning, where each agent has memory modules storing learned skills and routines. Cradle formalizes memory as separate from LLM parameters, allowing accumulation of expertise over tasks ([Cradle: Empowering Foundation Agents towards General Computer Control | OpenReview](https://openreview.net/forum?id=aIAFDFpNXz#:~:text=with%20software%20through%20the%20most,Experimental%20results%20show%20that)).
- **JARVIS-1 (Wang *et al.*, 2023)**: A multimodal agent in Minecraft equipped with a *multimodal memory* ([[2311.05997] JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models](https://arxiv.org/abs/2311.05997#:~:text=%3E%20Abstract%3AAchieving%20human,Specifically%2C%20we%20develop)). It stores visual-textual experiences from gameplay, using this growing memory to handle many tasks. Its memory module demonstrated performance leaps on long-horizon challenges by reusing accumulated knowledge.
- **LARP (Yan *et al.*, 2023)**: A language‐agent role-play system in games that explicitly includes a “memory processing” component ([[2312.17653] LARP: Language-Agent Role Play for Open-World Games](https://arxiv.org/abs/2312.17653#:~:text=,framework%20refines%20interactions%20between%20users)). LARP agents have an internal memory store (e.g. for character background) that informs their actions in open-world environments.

# Lifecycle: Memory Acquisition, Encoding, and Retrieval

**Acquisition (Compressing and Consolidating Experiences):**
- **HiAgent (Hu *et al.*, 2024)**: Besides short-term use, HiAgent implements an *experience replay* memory, compressing past frames into token embeddings (training-time memory) ([[2408.09559] HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model](https://arxiv.org/abs/2408.09559#:~:text=%3E%20Abstract%3ALarge%20Language%20Model%20%28LLM%29,the%20enhancement%20of%20agent%20performance)).
- **LMAgent (Liu *et al.*, 2024)**: Simulates a large society of agents with a fast-memory mechanism ([[2412.09237] LMAgent: A Large-scale Multimodal Agents Society for Multi-user Simulation](https://arxiv.org/abs/2412.09237#:~:text=consistency%20prompting%20mechanism%20to%20augment,scale%20social%20behavior%20simulations)). It stores each agent’s history compactly to allow 10,000+ agents to interact (e.g. chat, trading) efficiently.
- **ReadAgent (Lee *et al.*, 2024)**: A reading agent that compresses long texts into “gist” memories ([[2402.09727] A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts](https://arxiv.org/abs/2402.09727#:~:text=,We%20evaluate%20ReadAgent%20against)). It chunks documents into episodic memory slots, summarizing each into a short “gist” vector to extend effective context by 3–20× while still recalling details on demand.
- **ExpeL (Zhao *et al.*, 2024)**: An agent that **collects and consolidates experiences** from many tasks: it gathers success/failure episodes into memory, extracts high-level “insights,” and then recalls relevant past successes at test time ([ExpeL: LLM Agents Are Experiential Learners](https://arxiv.org/html/2308.10144v3#:~:text=We%20present%20the%20Experiential%20Learning,source)). By continuously consolidating experiences into language‐based knowledge, ExpeL exemplifies cross-task memory learning.
- **Unified Mind Model (Hu & Ying, 2025)**: Introduces *MindOS*, an OS-like framework with explicit long-term memory modules for agents ([[2503.03459] Unified Mind Model: Reimagining Autonomous Agents in the LLM Era](https://arxiv.org/abs/2503.03459#:~:text=creation%20of%20autonomous%20agents%20with,specific)). It highlights how memory (e.g. user profiles) can be easily added to agents for persistent knowledge, formalizing memory consolidation as part of agent design.

**Encoding (Selective Attention & Fusion):**
- **Agent-Corrd (Pan *et al.*, 2024)**: Uses attention to focus agents on relevant information. Each agent maintains its own memory stream; the system selectively attends to agents’ pertinent memories when planning, effectively compressing simultaneous chat history into salient cues (arXiv:2403.07464).
- **GraphVideoAgent (Chu *et al.*, 2025)**: Builds a dynamic video-knowledge graph from frames ([Understanding Long Videos via LLM-Powered Entity Relation Graphs](https://arxiv.org/html/2501.15953v1#:~:text=GraphVideoAgent%2C%20a%20cutting,improvement%20over%20existing)). It explicitly encodes visual memory of object relations over time, allowing selective reasoning about key events.
- **A-MEM (Xu *et al.*, 2025)**: Proposes a “zettelkasten” memory for agents ([[2502.12110] A-MEM: Agentic Memory for LLM Agents](https://arxiv.org/abs/2502.12110#:~:text=,When%20a)). Each new memory (experience) is converted into a structured note (context, keywords, etc.) and linked to related memories, dynamically reorganizing its knowledge base. This shows an advanced encoding scheme where new and old memories reshape each other.
- **Optimus-1 & 2 (Li *et al.*, 2024; 2025)**: Both in Minecraft use hybrid memory. Optimus-1 creates a hierarchical knowledge graph (knowledge memory) and an experience pool of past actions ([[2408.03615] Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks](https://arxiv.org/abs/2408.03615#:~:text=%3E%20Abstract%3ABuilding%20a%20general,context)), improving planning via selected historical experiences. Optimus-2 encodes goal-observation-action sequences as fixed “behavior tokens” ([[2502.19902] Optimus-2: Multimodal Minecraft Agent with Goal-Observation-Action Conditioned Policy](https://arxiv.org/abs/2502.19902#:~:text=in%20modeling%20the%20intricate%20relationships,Observation)), summarizing past behaviors for retrieval. These fusion techniques merge multimodal context into compact memory representations.
- **R2D2 (Huang *et al.*, 2025)**: For web navigation, introduces a *replay buffer* (remember) and a *reflective module*. The replay buffer encodes visited page states into a “map” of memory for navigation ([R2D2: Remembering, Reflecting and Dynamic Decision Making for Web Agents](https://arxiv.org/html/2501.12485v1#:~:text=understanding%20of%20web%20structures,R2D2%20using%20the%20WebArenabenchmark%2C%20demonstrating)), showing how sequential observations can be encoded for future decision-making.

**Retrieval and Derivation:**
- **SummEdits (Laban *et al.*, 2023)**: A benchmark for factual consistency, but its core idea is automatically generating “fact editing” prompts for LLMs to recall relevant info. Although not a memory system per se, it illustrates techniques (e.g. summarization) to retrieve factual details.
- **SCM (Wang *et al.*, 2023)**: A memory framework (the “Self-Controlled Memory” system) that decides which information to store and when to recall it ([[2304.13343] SCM: Enhancing Large Language Model with Self-Controlled Memory Framework](https://arxiv.org/abs/2304.13343#:~:text=,long%20texts)). It uses a memory stream and a controller that updates the stream contextually, demonstrating dynamic memory recall for dialog tasks.
- **Healthcare Copilot (Ren *et al.*, 2024)**: A medical dialog agent with a *Memory component* storing both current and historical patient info ([[2402.13408] Healthcare Copilot: Eliciting the Power of General LLMs for Medical Consultation](https://arxiv.org/abs/2402.13408#:~:text=,the%20proposed%20Healthcare%20Copilot%2C%20we)). It retrieves patient history to inform responses, showing how a retrieval mechanism improves personalized assistance.
- **KnowAgent (Zhu *et al.*, 2024)**: Builds an external *action knowledge base* that the agent queries during planning ([[2403.03101] KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents](https://arxiv.org/abs/2403.03101#:~:text=,action%20knowledge%20base%20and%20a)). Although focused on planning, this is a form of knowledge retrieval: the agent looks up relevant actions in memory to constrain its plan, reducing hallucination.
- **Agent-of-Thoughts Distillation (Shi *et al.*, 2024)**: Improves video‐LLMs by distilling chain-of-thoughts (CoT). It uses an agent to generate intermediate reasoning steps (stored as “thought memory”) and then retrains the model on these, thereby encoding retrieval of reasoning patterns into the model’s weights.
- **Selective Forgetting (memory pruning):** *Lyfe Agent* and *Temporal Latent Memories (TLM)* explore pruning or decaying old memories to keep agents focused (e.g. forgetting outdated context). *MemoryBank* also includes a forgetting policy to discard low-value memories ([Memory in Language Model-Enabled Agents](https://yuweisunn.github.io/blog-1-06-24.html#footnote-1#:~:text=MemoryBank%3A%20Enhancing%20Large%20Language%20Models,Term%20Memory%20%5B1)). These studies show that memory management is as important as storage.

**Retrieval (Indexing and Matching):**
- **HippoRAG (Gutierrez *et al.*, 2024)**: Implements hippocampal indexing: incoming queries are matched against memory embeddings using hybrid semantic-syntactic keys, enabling efficient retrieval of relevant chunks ([[2405.14831] HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models](https://arxiv.org/abs/2405.14831#:~:text=,HippoRAG)). It also uses PageRank over a memory graph for relevance (semantic matching).
- **TradingGPT (Li *et al.*, 2023)**: A financial agent with *layered memories* ([[2309.03736] TradingGPT: Multi-Agent System with Layered Memory and Distinct Characters for Enhanced Financial Trading Performance](https://arxiv.org/abs/2309.03736#:~:text=Title%3ATradingGPT%3A%20Multi,for%20Enhanced%20Financial%20Trading%20Performance)) ([[2309.03736] TradingGPT: Multi-Agent System with Layered Memory and Distinct Characters for Enhanced Financial Trading Performance](https://arxiv.org/abs/2309.03736#:~:text=prioritize%20immediate%20and%20critical%20tasks,This%20equips%20them)). It organizes short-term, mid-term, and long-term memories (with different decay rates) and uses weighted keys to retrieve pertinent past market events. This shows retrieval by multi-layered indexing.
- **LongMemEval (Wu *et al.*, 2024)**: A benchmark with an accompanying three-stage memory framework: indexing, retrieval, reading ([[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory](https://arxiv.org/abs/2410.10813#:~:text=,significant%20challenge%20to%20existing%20long)). It breaks memory retrieval into *indexing* (preparing keys), *retrieval* (fetching facts), and *reading* (using retrieved info), exemplifying systematic memory access design.
- **SeCom (Microsoft, 2025)**: Proposes building memory banks by topic segments and retrieving conversation history accordingly. (Preprint)
- **Matching Approaches:** *Product Key Memory* (Lample *et al.*, 2019) is an associative memory for Transformers that matches keys to retrieve embeddings for each token position. *OSAgent* (Xu *et al.*, 2024) uses memory-enhanced attention to match states to past experiences. These classic methods illustrate neural memory matching (product key lookups) to retrieve contextual memory.

# Neural Memory and Utilization

- **Hopfield Networks (Demircigil *et al.*, 2017; Ramsauer *et al.*, 2020)**: Modern Hopfield nets show how fixed associative memory (stored patterns) can be read out via attention-like updates. They serve as inspiration for content-addressable memories in LLMs, demonstrating high-capacity storage within attention mechanisms.
- **Neural Turing Machines (Graves *et al.*, 2014)**: Early neural memory model combining controller and external tape. It showed how a network can learn read/write operations to an explicit memory, laying groundwork for LLM retrieval modules.

- **MemoryLLM (Wang *et al.*, 2024)** and **Self-Param (Wang *et al.*, 2024)**: Both introduce ways to integrate memory-like storage into LLMs. MemoryLLM injects a learned memory layer to memorize rare facts, while Self-Param trains prompts as persistent memory. They exemplify parameter-based memory (storing information in weights/prompts) for long-term recall.
- **MemRAG (Qian *et al.*, 2025)**: A retrieval-augmented generation method for video that first compresses (memorizess) long video into memory and then performs retrieval augmented reasoning. It blends episodic video memory with RAG loops for answering queries, illustrating hybrid neural memory usage.
- **Titans (Behrouz *et al.*, 2024)** and **R³Mem (Wang *et al.*, 2025)**: These works propose reversible transformers and compression for memory: Titans “memorizes at test time” by recycling activations to store long context, while R³Mem uses reversible context compression to trade off retention vs retrieval ([R3Mem: Bridging Memory Retention and Retrieval via Reversible Compression](https://arxiv.org/html/2502.15957v1#:~:text=Memory%20plays%20a%20key%20role,histories%2C%20further%20enhanced%20by%20a)). Both achieve effective long-context memory by augmenting model internals, showing how architecture changes yield implicit memory.

**RAG (Retrieval-Augmented Generation):**
- **RAGLab (Zhang *et al.*, 2024)**: A toolkit for building RAG systems, emphasizing how to construct and query external knowledge stores in agents.
- **Adaptive Retrieval (Mallen *et al.*, 2023)**: Methods to dynamically choose which retrieval method (e.g. kNN vs hybrid) works best given the query, highlighting adaptive use of memory.
- **Atlas (Farahani *et al.*, 2024)**: Combines retrieval with structured knowledge (an “atlas”) to route queries. It organizes memories (knowledge) geographically for multimodal agents.

**Long-Context Modeling:**
- **RMT (Bulatov *et al.*, 2022; 2023)**: Recurrent Memory Transformer extends attention with recurrence, demonstrating memory across segments.
- **ICAE (Ge *et al.*, 2023)**: Uses an in-context autoencoder to compress long context into memory slots ([[2307.06945] In-context Autoencoder for Context Compression in a Large Language Model](https://arxiv.org/abs/2307.06945#:~:text=%3E%20Abstract%3AWe%20propose%20the%20In,times%24%20context%20compression%20based)). It pretrained a memory network so that the LLM can efficiently read from these compressed slots, improving long-context handling.
- **CompAct (Shamshoum *et al.*, 2024)**: A training technique compressing activations to reduce GPU memory usage ([[2410.15352] CompAct: Compressed Activations for Memory-Efficient LLM Training](https://arxiv.org/abs/2410.15352#:~:text=,compression%20uses%20random%20projection%20matrices)). Though focused on hardware efficiency, it effectively extends usable context length (by lowering memory costs), illustrating *memory-efficient training*.
- **ReadAgent (Lee *et al.*, 2024)**: As above, it pushes long-context by chunking content into “gist memories” ([[2402.09727] A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts](https://arxiv.org/abs/2402.09727#:~:text=,We%20evaluate%20ReadAgent%20against)).

**Alleviating Hallucination (Memory-Based Debiasing):**
- **Lamini Memory Tuning (Lamini.ai, 2024)**: A commercial approach (open source library) that injects factual knowledge into LLM weights (“memory tuning”) to reduce hallucinations.
- **PEER (He *et al.*, 2024)**: Peer instruction method for LLMs that consults an external memory of past examples to correct outputs (preprint).
- **Memoria (Park *et al.*, 2023)**: (If available) Encourages agents to retrieve and cite relevant context from a knowledge base during generation, using memory to ground responses.

The above papers illustrate how **memory modules**—whether explicit (databases, replay buffers), implicit (learned embeddings, compressed activations), or hybrid—enable intelligent agents to store experiences, retrieve relevant information, and ground their decisions in past context. Each contributes techniques (e.g. hierarchical graphs, retrieval-augmented generation, episodic diaries) that enrich agents’ cognition by endowing them with human-like memory capabilities ([CoPS: Empowering LLM Agents with Provable Cross-Task Experience Sharing](https://arxiv.org/html/2410.16670v1#:~:text=CoPS%3A%20Empowering%20LLM%20Agents%20with,Task%20Experience%20Sharing)) ([[2304.13343] SCM: Enhancing Large Language Model with Self-Controlled Memory Framework](https://arxiv.org/abs/2304.13343#:~:text=,long%20texts)).

**References:** We have drawn details from the cited papers (e.g. Wang *et al.* 2023 ([My title](https://arxiv.org/pdf/2306.02552#:~:text=2Beijing%20Key%20Laboratory%20of%20Big,evidences%20have%20suggested%20that%20by)), Chu *et al.* 2025 ([Understanding Long Videos via LLM-Powered Entity Relation Graphs](https://arxiv.org/html/2501.15953v1#:~:text=GraphVideoAgent%2C%20a%20cutting,improvement%20over%20existing)), Ge *et al.* 2024 ([[2404.18202] WorldGPT: Empowering LLM as Multimodal World Model](https://arxiv.org/abs/2404.18202#:~:text=Authors%3AZhiqi%20Ge%20%2C%20%2011%2C,15%2C%20Yueting%20Zhuang)) ([[2404.18202] WorldGPT: Empowering LLM as Multimodal World Model](https://arxiv.org/abs/2404.18202#:~:text=However%2C%20existing%20models%20are%20mainly,state%20transition%20prediction%20benchmark%20encompassing)), etc.), which provide full authorship, publication venue, and year for each work. Each link above points to the arXiv or official source for the paper.

